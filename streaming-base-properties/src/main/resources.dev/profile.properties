spark.master=local[*]
spark.app.name=spark.app.name
spark.streaming.concurrentJobs=20
spark.default.parallelism=32
spark.executor.extraJavaOptions=-XX:NewRatio=1 -XX:SurvivorRatio=8 -XX:+UseCompressedOops -XX:SoftRefLRUPolicyMSPerMB=0 -XX:MaxPermSize=512m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/apps/logs/spark/
spark.kryoserializer.buffer.mb=20
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.speculation=false
spark.storage.memoryFraction=0.3
spark.executor.logs.rolling.strategy=time
spark.executor.logs.rolling.time.interval=daily
spark.executor.logs.rolling.maxRetainedFiles=3


kmp.spark.streaming.duration=1
kmp.spark.streaming.window_duration=60
kmp.spark.streaming.slide_duration=1

kafka.zookeeper_host=spmaster:2187,spslave1:2187,spslave2:2187,spslave3:2187,spslave4:2187
kafka.group=kafka.group
kafka.topics=kafka.topic